### 4.1:

q_{\pi}(11, down) = -1
q_{\pi}(7, down) = -15

### 4.2:

v_{\pi}(15) = -19 then -20

### 4.3:

(4.3) q_{\pi}(s, a) = \mathbb(E)[R_{t+1} + \gamma.q_{\pi}(S_{t+1}, A_{t+1}) | S_t=s, A_t=a]
(4.4) q_{\pi}(s, a) = \sum_{s', r} p(s', r | s, a) [r + \gamma.\sum_{a'} \pi(a'|s').q_{\pi}(s', a')]
(4.5) q_{k+1}(s, a) = \sum_{s', r} p(s', r | s, a) [r + \gamma.\sum_{a'} \pi(a'|s').q_(s', a')]

### 4.4:

my solution: keep a list of past policies and stop when looping on past policy (see numpy/4/figures)

### 4.5:

cf. code in numpy/4/figures

### 4.6:

intuitive needed changes:
- in 3), make the argmax action have value \pi(a|s) of (|min(A(s))|-\epsilon)/|min(A(s))|, \epsilon/|min(A(s))|.
- in 2), make the update be a stochastic sum with \pi(a|s)
- in 1), make all the values be above |min(A(s))|

### 4.7

cf. code in numpy/4/figures

### 4.8

what i understand from the policy: it's trying to bet the amount necessary to get to 50, and then bet everything at 50. the intermediary steps are 25 and 75. so bets are centered around reaching either 0, 25, 50, 75 or 100.

the main strategy in betting all your money at 50 and not at 51 is that at 50 you NEED to play the "let's do this" plan. but at 51 you have this one extra cash that you can use to see if you can get higher?  

### 4.9

results are not stable as theta goes to 1e-15 (smallest float?) but the value function seems to become sharper and sharper and the peaks follow a trend (linear from 0 to 0.5, then from 0.5 to 0).

for p\_{heads} = 0.25 the value function is really close to Figure 4.3. My interpretation is that what really matters is p\_{heads} < 0.5 in this context.

for p\_{heads} = 0.55, the value function grows really smoothly, and the optimal policy is to always bet one (kinda of a random walk?) and then not move when having 99 in stocks ?! because moving would lead to the value of the final state (which is zero?).

### 4.10

q(s, a) = \sum_{r, s_p} p(s_p, r|s, a) (r + \gamma max_{a_p} q(s_p, a_p))
